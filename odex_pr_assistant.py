#!/usr/bin/env python3
"""
Codex Environment PR Assistant
Designed to run directly in Codex desktop/web environments with HTTP access enabled.

Required Environment Variables:
- OPENAI_API_KEY: Your OpenAI API key (sk-...)
- GITHUB_PERSONAL_ACCESS_TOKEN or GITHUB_TOKEN: GitHub personal access token (ghp_...)

Optional Environment Variables:
- CODEX_MODEL: AI model to use (default: gpt-4o)
  Available options: gpt-4o, gpt-4-turbo
"""

import requests
import json
import os
import sys
import time
from datetime import datetime
from typing import List, Dict

# Configuration
REPO = "Azizultra32/AliGGGG"  # Your actual repository
FILTER_LABEL = "needs-review"  # Set to None to review all PRs
MAX_PRS_TO_PROCESS = 5  # Limit to avoid rate limits


def get_codex_model():
    """Get the AI model to use for reviews with intelligent fallback."""
    model = os.getenv("CODEX_MODEL", "gpt-4o")  # Default to GPT-4 Omni
    valid_models = [
        "gpt-4o",
        "gpt-4-turbo",
        "gpt-4",
        "gpt-4-0613",
        "gpt-3.5-turbo",
    ]
    if model not in valid_models:
        print(f"âš ï¸ Unknown model '{model}', falling back to 'gpt-4o'")
        model = "gpt-4o"
    return model


def get_model_config():
    """Get model-specific configuration parameters."""
    model = get_codex_model()
    config = {
        "gpt-4o": {"max_tokens": 1200, "temperature": 0.2},
        "gpt-4-turbo": {"max_tokens": 1200, "temperature": 0.2},
        "gpt-4": {"max_tokens": 1000, "temperature": 0.2},
        "gpt-4-0613": {"max_tokens": 1000, "temperature": 0.2},
        "gpt-3.5-turbo": {"max_tokens": 800, "temperature": 0.3},
    }
    return model, config.get(model, {"max_tokens": 1000, "temperature": 0.2})

# API endpoints
GITHUB_API_BASE = "https://api.github.com"
OPENAI_API_BASE = "https://api.openai.com/v1"


def check_environment() -> bool:
    """Verify required environment variables and API access."""
    print("ğŸ” Checking Codex environment setup...")
    openai_key = os.getenv("OPENAI_API_KEY")
    github_token = os.getenv("GITHUB_PERSONAL_ACCESS_TOKEN") or os.getenv("GITHUB_TOKEN")
    if not openai_key:
        print("âŒ OPENAI_API_KEY not found in environment")
        return False
    if not github_token:
        print("âŒ GITHUB_PERSONAL_ACCESS_TOKEN not found in environment")
        return False
    print("âœ… Environment variables configured")
    print(f"âœ… OpenAI key: {openai_key[:12]}...{openai_key[-4:]}")
    print(f"âœ… GitHub token: {github_token[:8]}...{github_token[-4:]}")
    print(f"âœ… Target repository: {REPO}")
    return True


def test_api_access() -> bool:
    """Test API connectivity from Codex environment with model validation."""
    print("\nğŸŒ Testing API connectivity and model access...")
    try:
        github_token = os.getenv("GITHUB_PERSONAL_ACCESS_TOKEN") or os.getenv("GITHUB_TOKEN")
        headers = {"Authorization": f"token {github_token}", "Accept": "application/vnd.github.v3+json"}
        response = requests.get(f"{GITHUB_API_BASE}/user", headers=headers, timeout=10)
        if response.status_code == 200:
            user_data = response.json()
            print(f"âœ… GitHub API: Connected as @{user_data.get('login', 'Unknown')}")
        else:
            print(f"âŒ GitHub API: {response.status_code} - {response.text[:100]}")
            return False
        repo_response = requests.get(f"{GITHUB_API_BASE}/repos/{REPO}", headers=headers, timeout=10)
        if repo_response.status_code == 200:
            repo_data = repo_response.json()
            print(f"âœ… Repository access: {repo_data.get('full_name')} ({repo_data.get('private', 'public')})")
        else:
            print(f"âš ï¸ Repository access: {repo_response.status_code} - Check REPO setting")
    except Exception as exc:
        print(f"âŒ GitHub API connection failed: {exc}")
        return False
    try:
        openai_key = os.getenv("OPENAI_API_KEY")
        model, _ = get_model_config()
        headers = {"Authorization": f"Bearer {openai_key}", "Content-Type": "application/json"}
        test_payload = {
            "model": model,
            "messages": [{"role": "user", "content": "Test connection"}],
            "max_tokens": 5,
        }
        response = requests.post(f"{OPENAI_API_BASE}/chat/completions", headers=headers, json=test_payload, timeout=15)
        if response.status_code == 200:
            print(f"âœ… OpenAI API: Connected successfully using {model}")
        else:
            print(f"âŒ OpenAI API: {response.status_code} - {response.text[:100]}")
            return False
    except Exception as exc:
        print(f"âŒ OpenAI API connection failed: {exc}")
        return False
    print("ğŸš€ All systems ready for PR processing!")
    return True


def fetch_open_prs() -> List[Dict]:
    """Fetch open pull requests from the repository."""
    print(f"\nğŸ“¥ Fetching open PRs from {REPO}...")
    github_token = os.getenv("GITHUB_PERSONAL_ACCESS_TOKEN") or os.getenv("GITHUB_TOKEN")
    headers = {"Authorization": f"token {github_token}", "Accept": "application/vnd.github.v3+json"}
    try:
        response = requests.get(f"{GITHUB_API_BASE}/repos/{REPO}/pulls", headers=headers)
        response.raise_for_status()
        prs = response.json()
        print(f"âœ… Found {len(prs)} open PRs")
        if FILTER_LABEL:
            filtered_prs = []
            for pr in prs:
                labels = [label['name'] for label in pr.get('labels', [])]
                if FILTER_LABEL in labels:
                    filtered_prs.append(pr)
                else:
                    print(f"â­ï¸ Skipping PR #{pr['number']} ('{pr['title']}') - missing label '{FILTER_LABEL}'")
            prs = filtered_prs
            print(f"ğŸ·ï¸ After filtering by '{FILTER_LABEL}': {len(prs)} PRs")
        return prs[:MAX_PRS_TO_PROCESS]
    except requests.exceptions.RequestException as exc:
        print(f"âŒ Error fetching PRs: {exc}")
        return []


def get_pr_diff(pr_number: int) -> str:
    """Fetch the diff for a specific PR."""
    github_token = os.getenv("GITHUB_PERSONAL_ACCESS_TOKEN") or os.getenv("GITHUB_TOKEN")
    headers = {"Authorization": f"token {github_token}", "Accept": "application/vnd.github.v3.diff"}
    try:
        response = requests.get(f"{GITHUB_API_BASE}/repos/{REPO}/pulls/{pr_number}", headers=headers)
        response.raise_for_status()
        return response.text
    except requests.exceptions.RequestException as exc:
        print(f"âŒ Error fetching diff for PR #{pr_number}: {exc}")
        return ""


def analyze_with_codex(pr_number: int, pr_title: str, diff: str) -> str:
    """Send PR diff to Codex for analysis and review."""
    model, model_config = get_model_config()
    print(f"ğŸ§  Analyzing PR #{pr_number} with {model}...")
    openai_key = os.getenv("OPENAI_API_KEY")
    headers = {"Authorization": f"Bearer {openai_key}", "Content-Type": "application/json"}
    prompt = (
        f"You are a senior software engineer conducting a thorough GitHub code review."\
        f" Analyze this pull request systematically and provide a structured review.\n\n"
        f"PR #{pr_number}: {pr_title}\n\nDIFF:\n{diff}\n\n"
        "Please provide a comprehensive review with these specific sections:"\
        "\n\n## ğŸ“ Summary of Changes"\
        "\n- Brief overview of what this PR does"\
        "\n- Files modified and their purpose"\
        "\n\n## âš ï¸ Potential Issues & Conflicts"\
        "\n- Any merge conflicts or integration concerns"\
        "\n- Breaking changes or backward compatibility issues"\
        "\n- Security or performance implications"\
        "\n\n## ğŸ’¡ Suggestions for Improvements"\
        "\n- Code quality recommendations"\
        "\n- Best practices violations to address"\
        "\n- Optimization opportunities"\
        "\n\n## ğŸš¦ Merge Readiness Assessment"\
        "\n- Is this PR safe to merge? (Yes/No/Conditional)"\
        "\n- Required actions before merge"\
        "\n- Testing recommendations"\
    )
    payload = {
        "model": model,
        "messages": [
            {
                "role": "system",
                "content": "You are a senior software engineer with expertise in code review, conflict resolution, and software architecture. Provide thorough, actionable feedback.",
            },
            {"role": "user", "content": prompt},
        ],
        **model_config,
    }
    try:
        response = requests.post(f"{OPENAI_API_BASE}/chat/completions", headers=headers, json=payload, timeout=30)
        response.raise_for_status()
        result = response.json()
        review = result['choices'][0]['message']['content']
        review += "\n\n---\nğŸ§  _This review was generated by Codex AI. Please verify suggestions before merging._"
        return review
    except requests.exceptions.RequestException as exc:
        print(f"âŒ Error getting Codex review: {exc}")
        return f"âŒ Failed to generate review: {exc}"


def post_review_comment(pr_number: int, review: str) -> bool:
    """Post the Codex review as a comment on the PR."""
    print(f"ğŸ“ Posting review comment to PR #{pr_number}...")
    github_token = os.getenv("GITHUB_PERSONAL_ACCESS_TOKEN") or os.getenv("GITHUB_TOKEN")
    headers = {
        "Authorization": f"token {github_token}",
        "Accept": "application/vnd.github.v3+json",
        "Content-Type": "application/json",
    }
    comment_body = f"## ğŸ¤– Codex AI Review\n\n{review}"
    payload = {"body": comment_body}
    try:
        response = requests.post(
            f"{GITHUB_API_BASE}/repos/{REPO}/issues/{pr_number}/comments",
            headers=headers,
            json=payload,
        )
        response.raise_for_status()
        print(f"âœ… Review posted successfully to PR #{pr_number}")
        return True
    except requests.exceptions.RequestException as exc:
        print(f"âŒ Error posting comment to PR #{pr_number}: {exc}")
        return False


def log_review(pr_number: int, pr_title: str, review: str) -> None:
    """Log review details for auditing."""
    timestamp = datetime.utcnow().isoformat() + "Z"
    print(f"\n{'='*80}")
    print(f"## ğŸ“‹ Review Summary for PR #{pr_number}")
    print(f"**Title:** {pr_title}")
    print(f"**Timestamp:** {timestamp}")
    print(f"{'='*80}")
    print(review)
    print(f"{'='*80}")
    review_data = {
        "pr_number": pr_number,
        "title": pr_title,
        "timestamp": timestamp,
        "review_length_chars": len(review),
        "review_length_words": len(review.split()),
        "status": "completed",
        "repo": REPO,
    }
    print("\n```json")
    print(json.dumps(review_data, indent=2))
    print("```")
    try:
        audit_entry = f"\n---\n### PR #{pr_number}: {pr_title}\nğŸ•’ {timestamp}\nğŸ“Š Repository: {REPO}\n\n{review}\n\n"
        with open("codex_review_audit.md", "a", encoding="utf-8") as file:
            file.write(audit_entry)
        print("ğŸ“ Also logged to codex_review_audit.md")
    except Exception:
        print("ğŸ“ Web environment - audit saved to output above")


def main() -> None:
    """Main execution function."""
    print("ğŸš€ Codex PR Assistant - Enhanced Edition")
    print("=" * 60)
    print("\nğŸ“‹ STEP 1: Environment Validation")
    if not check_environment():
        print("\nâŒ Environment setup incomplete. Please configure your API keys.")
        return
    print("\nğŸ“‹ STEP 2: API Connectivity Test")
    if not test_api_access():
        print("\nâŒ API connectivity failed. Check your tokens and network access.")
        return
    print(f"\nğŸ“‹ STEP 3: PR Discovery and Filtering")
    open_prs = fetch_open_prs()
    if not open_prs:
        print("âœ… No PRs found matching criteria.")
        if FILTER_LABEL:
            print(f"ğŸ’¡ PRs must be labeled '{FILTER_LABEL}' to be processed")
        return
    print(f"ğŸ¯ Found {len(open_prs)} PRs to process")
    print(f"\nğŸ“‹ STEP 4: PR Review Processing")
    successful_reviews = 0
    failed_reviews = 0
    for i, pr in enumerate(open_prs, 1):
        pr_number = pr['number']
        pr_title = pr['title']
        print(f"\nğŸ”„ [{i}/{len(open_prs)}] Processing PR #{pr_number}")
        print(f"ğŸ“ Title: {pr_title}")
        try:
            print("   ğŸ“¥ Fetching diff...")
            diff = get_pr_diff(pr_number)
            if not diff.strip():
                print("   âš ï¸ Empty diff - skipping")
                continue
            print("   ğŸ§  Analyzing with Codex...")
            review = analyze_with_codex(pr_number, pr_title, diff)
            print("   ğŸ“¤ Posting review comment...")
            success = post_review_comment(pr_number, review)
            if success:
                log_review(pr_number, pr_title, review)
                print("   âœ… Review completed successfully")
                successful_reviews += 1
            else:
                print("   âš ï¸ Partial completion - review generated but not posted")
                failed_reviews += 1
        except Exception as exc:
            print(f"   âŒ Error: {exc}")
            failed_reviews += 1
        if i < len(open_prs):
            print("   â³ Rate limiting pause...")
            time.sleep(2)
    print(f"\nğŸ“‹ STEP 5: Completion Summary")
    print("=" * 60)
    print("ğŸ‰ Codex PR Assistant completed!")
    print("ğŸ“Š Results:")
    print(f"   âœ… Successful reviews: {successful_reviews}")
    print(f"   âŒ Failed reviews: {failed_reviews}")
    print(f"   ğŸ“ Total processed: {successful_reviews + failed_reviews}")
    print(f"   ğŸ¯ Repository: {REPO}")
    print("=" * 60)
    if successful_reviews > 0:
        print("ğŸ’¡ Check the GitHub PRs for posted reviews!")
    if failed_reviews > 0:
        print("âš ï¸ Some reviews failed - check error messages above")


if __name__ == "__main__":
    print("ğŸ”§ Codex PR Assistant - Pre-flight Check")
    print("-" * 50)
    if REPO == "YOUR_USERNAME/YOUR_REPO_NAME":
        print("âŒ CONFIGURATION REQUIRED:\n   Please update the REPO variable with your actual repository")
        sys.exit(1)
    if not REPO or "/" not in REPO:
        print("âŒ INVALID REPO FORMAT:\n   REPO must be in format 'username/repository'")
        sys.exit(1)
    print(f"âœ… Repository configured: {REPO}")
    model, model_config = get_model_config()
    print(f"âœ… AI Model: {model}")
    print(f"âœ… Model Config: {model_config}")
    if os.getenv("CODEX_MODEL"):
        print("âœ… Custom model from CODEX_MODEL environment variable")
    else:
        print("ğŸ’¡ Tip: Set CODEX_MODEL environment variable to use different model")
    if FILTER_LABEL:
        print(f"âœ… PR filter: Only processing PRs labeled '{FILTER_LABEL}'")
    else:
        print("âœ… PR filter: Processing ALL open PRs")
    print("-" * 50)
    main()
